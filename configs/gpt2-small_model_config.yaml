pretrained_name: "gpt2"
lr: 0.0001
epochs: 50
train_context: 0.
adaptation_part: 0.25
div_factor: 10000
log_dir: "./gpt2-small"