pretrained_name: &global_name "bert-large-uncased" # "bert-large-cased" / "bert-large-uncased"
lr: 0.0001
epochs: 20
adaptation_epochs: 5
div_factor: 10000
log_dir: "./bert-large"
# For input data
pretrained_tokenizer: *global_name
max_token_number: 256 # 100 #
batch_size: 32